{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_path = os.path.abspath(\".\")\n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_path, '..', 'src')))\n",
    "\n",
    "import encoding_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kilometraje</th>\n",
       "      <th>cambio_automatico</th>\n",
       "      <th>potencia</th>\n",
       "      <th>marca_sola</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>precio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.095147</td>\n",
       "      <td>1</td>\n",
       "      <td>5.505332</td>\n",
       "      <td>BMW</td>\n",
       "      <td>14</td>\n",
       "      <td>9.898525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.904974</td>\n",
       "      <td>1</td>\n",
       "      <td>5.609472</td>\n",
       "      <td>BMW</td>\n",
       "      <td>18</td>\n",
       "      <td>9.510519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.745076</td>\n",
       "      <td>1</td>\n",
       "      <td>5.572154</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>6</td>\n",
       "      <td>11.181654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.644331</td>\n",
       "      <td>1</td>\n",
       "      <td>5.942799</td>\n",
       "      <td>LEXUS</td>\n",
       "      <td>18</td>\n",
       "      <td>9.384378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.272012</td>\n",
       "      <td>1</td>\n",
       "      <td>5.726848</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>9</td>\n",
       "      <td>10.791399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19885</th>\n",
       "      <td>9.752839</td>\n",
       "      <td>1</td>\n",
       "      <td>5.303305</td>\n",
       "      <td>MERCEDES-BENZ</td>\n",
       "      <td>1</td>\n",
       "      <td>10.776892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19886</th>\n",
       "      <td>10.101108</td>\n",
       "      <td>1</td>\n",
       "      <td>5.303305</td>\n",
       "      <td>MERCEDES-BENZ</td>\n",
       "      <td>1</td>\n",
       "      <td>10.776892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19887</th>\n",
       "      <td>11.577908</td>\n",
       "      <td>1</td>\n",
       "      <td>5.273000</td>\n",
       "      <td>MERCEDES-BENZ</td>\n",
       "      <td>4</td>\n",
       "      <td>10.568775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19888</th>\n",
       "      <td>11.347933</td>\n",
       "      <td>1</td>\n",
       "      <td>4.812184</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>4</td>\n",
       "      <td>9.908525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19889</th>\n",
       "      <td>9.484937</td>\n",
       "      <td>0</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>PEUGEOT</td>\n",
       "      <td>1</td>\n",
       "      <td>10.042858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18206 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       kilometraje  cambio_automatico  potencia     marca_sola  antiguedad  \\\n",
       "0        12.095147                  1  5.505332            BMW          14   \n",
       "1        11.904974                  1  5.609472            BMW          18   \n",
       "2        10.745076                  1  5.572154         TOYOTA           6   \n",
       "3        12.644331                  1  5.942799          LEXUS          18   \n",
       "4        11.272012                  1  5.726848          TESLA           9   \n",
       "...            ...                ...       ...            ...         ...   \n",
       "19885     9.752839                  1  5.303305  MERCEDES-BENZ           1   \n",
       "19886    10.101108                  1  5.303305  MERCEDES-BENZ           1   \n",
       "19887    11.577908                  1  5.273000  MERCEDES-BENZ           4   \n",
       "19888    11.347933                  1  4.812184         TOYOTA           4   \n",
       "19889     9.484937                  0  4.875197        PEUGEOT           1   \n",
       "\n",
       "          precio  \n",
       "0       9.898525  \n",
       "1       9.510519  \n",
       "2      11.181654  \n",
       "3       9.384378  \n",
       "4      10.791399  \n",
       "...          ...  \n",
       "19885  10.776892  \n",
       "19886  10.776892  \n",
       "19887  10.568775  \n",
       "19888   9.908525  \n",
       "19889  10.042858  \n",
       "\n",
       "[18206 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelo = pd.read_pickle('../bin/dataframe_ml.pickle')\n",
    "df_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../bin/marca_sola_precio_encoder.pickle\", \"rb\") as file:\n",
    "    marca_sola_precio_encoder = pickle.load(file)\n",
    "\n",
    "with open(f\"../bin/min_max_scaler.pickle\", \"rb\") as file:\n",
    "    min_max_scaler = pickle.load(file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con one hot encoding en su lugar para marca\n",
    "# encoding_func.generar_pickle_onehot_encoding(df_modelo, ['marca_sola'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"../bin/marca_sola_precio_encoder.pickle\", \"rb\") as file:\n",
    "#     marca_sola_encoder = pickle.load(file)\n",
    "\n",
    "# with open(f\"../bin/min_max_scaler.pickle\", \"rb\") as file:\n",
    "#     min_max_scaler = pickle.load(file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"precio\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = encoding_func.dividir_dataframe(df_modelo, TARGET, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train[\"marca_sola\"] = marca_sola_precio_encoder.transform(X_train[\"marca_sola\"])\n",
    "X_test[\"marca_sola\"] = marca_sola_precio_encoder.transform(X_test[\"marca_sola\"])\n",
    "\n",
    "X_train = min_max_scaler.transform(X_train)\n",
    "X_test = min_max_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# scaler.set_output(transform=\"pandas\")\n",
    "\n",
    "# X_train_escalado = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "# X_test_escalado = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kilometraje</th>\n",
       "      <th>cambio_automatico</th>\n",
       "      <th>potencia</th>\n",
       "      <th>marca_sola</th>\n",
       "      <th>antiguedad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18983</th>\n",
       "      <td>0.731146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503202</td>\n",
       "      <td>0.250029</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>0.875992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.598995</td>\n",
       "      <td>0.369963</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>0.676674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.443408</td>\n",
       "      <td>0.190508</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.916511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.549681</td>\n",
       "      <td>0.212039</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>0.810555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684449</td>\n",
       "      <td>0.491206</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11891</th>\n",
       "      <td>0.776087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.503202</td>\n",
       "      <td>0.077735</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12761</th>\n",
       "      <td>0.906479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.598995</td>\n",
       "      <td>0.502655</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>0.828474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.592297</td>\n",
       "      <td>0.377722</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0.431142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.519865</td>\n",
       "      <td>0.073555</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17130</th>\n",
       "      <td>0.855176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521461</td>\n",
       "      <td>0.077735</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14564 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       kilometraje  cambio_automatico  potencia  marca_sola  antiguedad\n",
       "18983     0.731146                0.0  0.503202    0.250029    0.033333\n",
       "6177      0.875992                1.0  0.598995    0.369963    0.133333\n",
       "10801     0.676674                0.0  0.443408    0.190508    0.033333\n",
       "177       0.916511                1.0  0.549681    0.212039    0.300000\n",
       "3932      0.810555                1.0  0.684449    0.491206    0.066667\n",
       "...            ...                ...       ...         ...         ...\n",
       "11891     0.776087                1.0  0.503202    0.077735    0.100000\n",
       "12761     0.906479                1.0  0.598995    0.502655    0.266667\n",
       "5559      0.828474                1.0  0.592297    0.377722    0.100000\n",
       "868       0.431142                1.0  0.519865    0.073555    0.033333\n",
       "17130     0.855176                1.0  0.521461    0.077735    0.100000\n",
       "\n",
       "[14564 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RED NEURONAL DE REGRESIÓN ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_modelo(numero_entradas):\n",
    "    \"\"\"Crea un modelo de red neuronal secuencial para regresión.\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Capa de entrada\n",
    "    model.add(Dense(units=64, activation='relu', input_dim=numero_entradas))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "    # learning_rate = 0.01  # Ajusta este valor\n",
    "    # optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def entrenar_modelo(model, X_train, y_train, epochs=100, batch_size=32):\n",
    "    \"\"\"Entrena el modelo de red neuronal y guarda el historial de entrenamiento.\"\"\"\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\",\n",
    "                                   patience=15,\n",
    "                                   restore_best_weights=True)\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[early_stopping])\n",
    "     \n",
    "    return model, history\n",
    "\n",
    "def obtener_predicciones(model, X_test):\n",
    "    \"\"\"Obtiene las predicciones del modelo.\"\"\"\n",
    "    return model.predict(X_test).flatten()\n",
    "\n",
    "def evaluar_modelo(y_test, y_pred):\n",
    "    \"\"\"Evalúa el rendimiento del modelo de regresión.\"\"\"\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, mae, r2\n",
    "\n",
    "def graficar_historial(history):\n",
    "    \"\"\"Grafica el historial de entrenamiento (loss y MAE) y guarda la imagen.\"\"\"\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Loss vs. Epochs\", \"MAE vs. Epochs\"))\n",
    "\n",
    "    # Gráfica de Loss\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(history.history['loss']))),\n",
    "        y=history.history['loss'],\n",
    "        mode='lines',\n",
    "        name='Training Loss'\n",
    "    ), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(history.history['val_loss']))),\n",
    "        y=history.history['val_loss'],\n",
    "        mode='lines',\n",
    "        name='Validation Loss'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    # Gráfica de MAE\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(history.history['mae']))),\n",
    "        y=history.history['mae'],\n",
    "        mode='lines',\n",
    "        name='Training MAE'\n",
    "    ), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(len(history.history['val_mae']))),\n",
    "        y=history.history['val_mae'],\n",
    "        mode='lines',\n",
    "        name='Validation MAE'\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text='Training History',\n",
    "        xaxis_title='Epochs',\n",
    "        yaxis_title='Loss',\n",
    "        yaxis2=dict(\n",
    "            title='MAE',\n",
    "            overlaying='y',\n",
    "            side='right'\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top',\n",
    "            font=dict(size=10),\n",
    "            bgcolor='rgba(255, 255, 255, 0)',\n",
    "            bordercolor='rgba(255, 255, 255, 0)'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Guardar la imagen\n",
    "    #fig.write_image('../img/graficas_dl.png')\n",
    "    #fig.show()\n",
    "\n",
    "def main(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Función principal que ejecuta todo el proceso de modelado.\"\"\"\n",
    "    model = crear_modelo(X_train.shape[1])\n",
    "    model, history = entrenar_modelo(model, X_train, y_train)\n",
    "\n",
    "    model.save('../bin/modelo_dl.keras')\n",
    "    with open('../bin/modelo_dl_architecture.json', 'w') as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "\n",
    "    with open('../bin/history_dl.pickle', 'wb') as file:\n",
    "        pickle.dump(history.history, file)\n",
    "\n",
    "    y_pred = obtener_predicciones(model, X_test)\n",
    "    mse, mae, r2 = evaluar_modelo(y_test, y_pred)\n",
    "\n",
    "    print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "    df_metrics = pd.DataFrame({\n",
    "        'MSE': [mse],\n",
    "        'MAE': [mae],\n",
    "        'R2': [r2]\n",
    "    })\n",
    "    with open('../bin/metrics_dl.pickle', 'wb') as file:\n",
    "        pickle.dump(df_metrics, file)\n",
    "\n",
    "    graficar_historial(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\hackABoss\\pfb-coches\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,497</span> (9.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,497\u001b[0m (9.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,497</span> (9.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,497\u001b[0m (9.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 41.4851 - mae: 5.1283 - val_loss: 0.2755 - val_mae: 0.3783\n",
      "Epoch 2/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1595 - mae: 0.2820 - val_loss: 0.0699 - val_mae: 0.1931\n",
      "Epoch 3/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0676 - mae: 0.1892 - val_loss: 0.0611 - val_mae: 0.1761\n",
      "Epoch 4/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0658 - mae: 0.1773 - val_loss: 0.0605 - val_mae: 0.1748\n",
      "Epoch 5/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0628 - mae: 0.1725 - val_loss: 0.0553 - val_mae: 0.1641\n",
      "Epoch 6/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0535 - mae: 0.1646 - val_loss: 0.0568 - val_mae: 0.1658\n",
      "Epoch 7/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0612 - mae: 0.1687 - val_loss: 0.0560 - val_mae: 0.1621\n",
      "Epoch 8/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0619 - mae: 0.1681 - val_loss: 0.0534 - val_mae: 0.1581\n",
      "Epoch 9/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0595 - mae: 0.1619 - val_loss: 0.0524 - val_mae: 0.1567\n",
      "Epoch 10/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0563 - mae: 0.1647 - val_loss: 0.0539 - val_mae: 0.1597\n",
      "Epoch 11/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0563 - mae: 0.1631 - val_loss: 0.0539 - val_mae: 0.1616\n",
      "Epoch 12/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0549 - mae: 0.1612 - val_loss: 0.0528 - val_mae: 0.1584\n",
      "Epoch 13/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0572 - mae: 0.1628 - val_loss: 0.0564 - val_mae: 0.1664\n",
      "Epoch 14/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0536 - mae: 0.1612 - val_loss: 0.0517 - val_mae: 0.1563\n",
      "Epoch 15/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0541 - mae: 0.1606 - val_loss: 0.0599 - val_mae: 0.1733\n",
      "Epoch 16/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0571 - mae: 0.1585 - val_loss: 0.0542 - val_mae: 0.1650\n",
      "Epoch 17/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0610 - mae: 0.1638 - val_loss: 0.0731 - val_mae: 0.2076\n",
      "Epoch 18/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0543 - mae: 0.1667 - val_loss: 0.0599 - val_mae: 0.1807\n",
      "Epoch 19/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0542 - mae: 0.1622 - val_loss: 0.0563 - val_mae: 0.1672\n",
      "Epoch 20/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0545 - mae: 0.1648 - val_loss: 0.0525 - val_mae: 0.1651\n",
      "Epoch 21/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0517 - mae: 0.1609 - val_loss: 0.0473 - val_mae: 0.1504\n",
      "Epoch 22/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0533 - mae: 0.1571 - val_loss: 0.0482 - val_mae: 0.1517\n",
      "Epoch 23/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0524 - mae: 0.1581 - val_loss: 0.0474 - val_mae: 0.1498\n",
      "Epoch 24/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0497 - mae: 0.1540 - val_loss: 0.0543 - val_mae: 0.1648\n",
      "Epoch 25/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0528 - mae: 0.1597 - val_loss: 0.0478 - val_mae: 0.1536\n",
      "Epoch 26/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0475 - mae: 0.1557 - val_loss: 0.0467 - val_mae: 0.1495\n",
      "Epoch 27/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0501 - mae: 0.1582 - val_loss: 0.0535 - val_mae: 0.1723\n",
      "Epoch 28/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0506 - mae: 0.1570 - val_loss: 0.0722 - val_mae: 0.1996\n",
      "Epoch 29/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0498 - mae: 0.1573 - val_loss: 0.0454 - val_mae: 0.1487\n",
      "Epoch 30/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0529 - mae: 0.1587 - val_loss: 0.0503 - val_mae: 0.1567\n",
      "Epoch 31/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0519 - mae: 0.1581 - val_loss: 0.0593 - val_mae: 0.1876\n",
      "Epoch 32/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0496 - mae: 0.1570 - val_loss: 0.0562 - val_mae: 0.1709\n",
      "Epoch 33/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0502 - mae: 0.1586 - val_loss: 0.0537 - val_mae: 0.1653\n",
      "Epoch 34/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0553 - mae: 0.1603 - val_loss: 0.0602 - val_mae: 0.1899\n",
      "Epoch 35/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0493 - mae: 0.1595 - val_loss: 0.0456 - val_mae: 0.1505\n",
      "Epoch 36/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0475 - mae: 0.1573 - val_loss: 0.0445 - val_mae: 0.1487\n",
      "Epoch 37/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0528 - mae: 0.1564 - val_loss: 0.0453 - val_mae: 0.1501\n",
      "Epoch 38/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0485 - mae: 0.1526 - val_loss: 0.0504 - val_mae: 0.1664\n",
      "Epoch 39/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0451 - mae: 0.1537 - val_loss: 0.0485 - val_mae: 0.1564\n",
      "Epoch 40/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0522 - mae: 0.1562 - val_loss: 0.0537 - val_mae: 0.1648\n",
      "Epoch 41/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0489 - mae: 0.1561 - val_loss: 0.0458 - val_mae: 0.1557\n",
      "Epoch 42/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0495 - mae: 0.1595 - val_loss: 0.0469 - val_mae: 0.1546\n",
      "Epoch 43/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0510 - mae: 0.1568 - val_loss: 0.0429 - val_mae: 0.1477\n",
      "Epoch 44/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0589 - mae: 0.1596 - val_loss: 0.0473 - val_mae: 0.1567\n",
      "Epoch 45/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0560 - mae: 0.1624 - val_loss: 0.0451 - val_mae: 0.1529\n",
      "Epoch 46/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0480 - mae: 0.1541 - val_loss: 0.0442 - val_mae: 0.1504\n",
      "Epoch 47/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0472 - mae: 0.1526 - val_loss: 0.0433 - val_mae: 0.1461\n",
      "Epoch 48/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0458 - mae: 0.1527 - val_loss: 0.0545 - val_mae: 0.1704\n",
      "Epoch 49/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0472 - mae: 0.1547 - val_loss: 0.0429 - val_mae: 0.1463\n",
      "Epoch 50/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0535 - mae: 0.1548 - val_loss: 0.0433 - val_mae: 0.1474\n",
      "Epoch 51/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0469 - mae: 0.1526 - val_loss: 0.0431 - val_mae: 0.1489\n",
      "Epoch 52/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0488 - mae: 0.1539 - val_loss: 0.0473 - val_mae: 0.1546\n",
      "Epoch 53/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0545 - mae: 0.1568 - val_loss: 0.0441 - val_mae: 0.1528\n",
      "Epoch 54/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0540 - mae: 0.1550 - val_loss: 0.0457 - val_mae: 0.1500\n",
      "Epoch 55/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0462 - mae: 0.1534 - val_loss: 0.0453 - val_mae: 0.1546\n",
      "Epoch 56/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0469 - mae: 0.1555 - val_loss: 0.0433 - val_mae: 0.1494\n",
      "Epoch 57/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0504 - mae: 0.1597 - val_loss: 0.0469 - val_mae: 0.1532\n",
      "Epoch 58/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0508 - mae: 0.1569 - val_loss: 0.0426 - val_mae: 0.1473\n",
      "Epoch 59/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0446 - mae: 0.1502 - val_loss: 0.0454 - val_mae: 0.1509\n",
      "Epoch 60/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0586 - mae: 0.1595 - val_loss: 0.0434 - val_mae: 0.1504\n",
      "Epoch 61/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0477 - mae: 0.1513 - val_loss: 0.0492 - val_mae: 0.1665\n",
      "Epoch 62/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0476 - mae: 0.1555 - val_loss: 0.0424 - val_mae: 0.1480\n",
      "Epoch 63/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0474 - mae: 0.1541 - val_loss: 0.0498 - val_mae: 0.1665\n",
      "Epoch 64/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0491 - mae: 0.1554 - val_loss: 0.0590 - val_mae: 0.1763\n",
      "Epoch 65/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0535 - mae: 0.1642 - val_loss: 0.0429 - val_mae: 0.1487\n",
      "Epoch 66/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0461 - mae: 0.1506 - val_loss: 0.0461 - val_mae: 0.1588\n",
      "Epoch 67/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0449 - mae: 0.1502 - val_loss: 0.0423 - val_mae: 0.1479\n",
      "Epoch 68/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0487 - mae: 0.1542 - val_loss: 0.0492 - val_mae: 0.1638\n",
      "Epoch 69/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0479 - mae: 0.1533 - val_loss: 0.0431 - val_mae: 0.1492\n",
      "Epoch 70/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0449 - mae: 0.1502 - val_loss: 0.0453 - val_mae: 0.1546\n",
      "Epoch 71/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0447 - mae: 0.1528 - val_loss: 0.0505 - val_mae: 0.1698\n",
      "Epoch 72/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0538 - mae: 0.1594 - val_loss: 0.0431 - val_mae: 0.1472\n",
      "Epoch 73/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0497 - mae: 0.1523 - val_loss: 0.0434 - val_mae: 0.1479\n",
      "Epoch 74/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0507 - mae: 0.1586 - val_loss: 0.0419 - val_mae: 0.1478\n",
      "Epoch 75/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0457 - mae: 0.1495 - val_loss: 0.0460 - val_mae: 0.1532\n",
      "Epoch 76/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0454 - mae: 0.1500 - val_loss: 0.0441 - val_mae: 0.1487\n",
      "Epoch 77/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0522 - mae: 0.1566 - val_loss: 0.0442 - val_mae: 0.1494\n",
      "Epoch 78/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0465 - mae: 0.1524 - val_loss: 0.0453 - val_mae: 0.1567\n",
      "Epoch 79/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0490 - mae: 0.1543 - val_loss: 0.0440 - val_mae: 0.1493\n",
      "Epoch 80/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0447 - mae: 0.1522 - val_loss: 0.0429 - val_mae: 0.1475\n",
      "Epoch 81/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0447 - mae: 0.1525 - val_loss: 0.0425 - val_mae: 0.1473\n",
      "Epoch 82/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0451 - mae: 0.1516 - val_loss: 0.0423 - val_mae: 0.1492\n",
      "Epoch 83/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0445 - mae: 0.1500 - val_loss: 0.0471 - val_mae: 0.1550\n",
      "Epoch 84/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0469 - mae: 0.1532 - val_loss: 0.0472 - val_mae: 0.1622\n",
      "Epoch 85/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0432 - mae: 0.1484 - val_loss: 0.0469 - val_mae: 0.1616\n",
      "Epoch 86/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0455 - mae: 0.1535 - val_loss: 0.0423 - val_mae: 0.1468\n",
      "Epoch 87/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0508 - mae: 0.1511 - val_loss: 0.0418 - val_mae: 0.1464\n",
      "Epoch 88/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0467 - mae: 0.1538 - val_loss: 0.0437 - val_mae: 0.1482\n",
      "Epoch 89/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0516 - mae: 0.1580 - val_loss: 0.0440 - val_mae: 0.1486\n",
      "Epoch 90/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0460 - mae: 0.1511 - val_loss: 0.0449 - val_mae: 0.1567\n",
      "Epoch 91/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0458 - mae: 0.1532 - val_loss: 0.0438 - val_mae: 0.1516\n",
      "Epoch 92/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0457 - mae: 0.1529 - val_loss: 0.0521 - val_mae: 0.1734\n",
      "Epoch 93/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0449 - mae: 0.1512 - val_loss: 0.0474 - val_mae: 0.1572\n",
      "Epoch 94/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0428 - mae: 0.1496 - val_loss: 0.0446 - val_mae: 0.1500\n",
      "Epoch 95/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0498 - mae: 0.1534 - val_loss: 0.0422 - val_mae: 0.1461\n",
      "Epoch 96/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0446 - mae: 0.1491 - val_loss: 0.0425 - val_mae: 0.1464\n",
      "Epoch 97/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0488 - mae: 0.1546 - val_loss: 0.0565 - val_mae: 0.1826\n",
      "Epoch 98/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0513 - mae: 0.1570 - val_loss: 0.0420 - val_mae: 0.1475\n",
      "Epoch 99/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0442 - mae: 0.1508 - val_loss: 0.0483 - val_mae: 0.1643\n",
      "Epoch 100/100\n",
      "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0465 - mae: 0.1545 - val_loss: 0.0501 - val_mae: 0.1700\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "MSE: 0.0392, MAE: 0.1428, R^2: 0.8735\n"
     ]
    }
   ],
   "source": [
    "main(X_train, X_test, y_train, y_test)\n",
    "#X_train[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n"
     ]
    }
   ],
   "source": [
    "modelo = tf.keras.models.load_model(\"../bin/modelo_dl.keras\")\n",
    "\n",
    "y_pred = obtener_predicciones(modelo, X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(18400.537)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RED NEURONAL DENSA ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_dnn(input_dim):\n",
    "    \"\"\"Crea una Red Neuronal Densa (DNN) para regresión.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    model.summary()\n",
    "   \n",
    "\n",
    "    return model\n",
    "\n",
    "def entrenar_dnn(model, X_train, y_train, epochs=100, batch_size=32):\n",
    "    \"\"\"Entrena la DNN y guarda el historial de entrenamiento.\"\"\"\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.2)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def obtener_predicciones_dnn(model, X_test):\n",
    "    \"\"\"Obtiene las predicciones de la DNN.\"\"\"\n",
    "    return model.predict(X_test).flatten()\n",
    "\n",
    "def evaluar_dnn(y_test, y_pred):\n",
    "    \"\"\"Evalúa el rendimiento de la DNN.\"\"\"\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, mae, r2\n",
    "\n",
    "def graficar_historial_dnn(history):\n",
    "    \"\"\"Grafica el historial de entrenamiento (loss y MAE).\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Gráfica de Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss vs. Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Gráfica de MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.title('MAE vs. Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def main_dnn(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Función principal que ejecuta todo el proceso de modelado con la DNN.\"\"\"\n",
    "    model = crear_dnn(X_train.shape[1])\n",
    "    model, history = entrenar_dnn(model, X_train, y_train)\n",
    "\n",
    "    y_pred = obtener_predicciones_dnn(model, X_test)\n",
    "    mse, mae, r2 = evaluar_dnn(y_test, y_pred)\n",
    "\n",
    "    print(f\"DNN - MSE: {mse:.4f}, MAE: {mae:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "    graficar_historial_dnn(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dnn(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RED NEURONAL DE REGRESIÓN CON DISTINTOS PARÁMETROS ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Input\n",
    "\n",
    "def crear_modelo(entradas):\n",
    "    \"\"\"Crea un modelo de red neuronal secuencial para regresión.\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Capa de entrada\n",
    "    model.add(Dense(units = 64, activation='relu', input_dim=entradas))\n",
    "\n",
    "    model.add(Dense(units = 32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(units = 1))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def entrenar_modelo(model, X_train, y_train, epochs=100):\n",
    "    \"\"\"Entrena el modelo de red neuronal y guarda el historial de entrenamiento.\"\"\"\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2)\n",
    "    return model, history\n",
    "\n",
    "def obtener_predicciones(model, X_test):\n",
    "    \"\"\"Obtiene las predicciones del modelo.\"\"\"\n",
    "    return model.predict(X_test).flatten()\n",
    "\n",
    "def evaluar_modelo(y_test, y_pred):\n",
    "    \"\"\"Evalúa el rendimiento del modelo de regresión.\"\"\"\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, mae, r2\n",
    "\n",
    "def graficar_historial(history):\n",
    "    \"\"\"Grafica el historial de entrenamiento (loss y MAE).\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Gráfica de Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss vs. Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Gráfica de MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.title('MAE vs. Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def main_otrosp(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Función principal que ejecuta todo el proceso de modelado.\"\"\"\n",
    "    model = crear_modelo(X_train.shape[1])\n",
    "    model, history = entrenar_modelo(model, X_train, y_train)\n",
    "\n",
    "    y_pred = obtener_predicciones(model, X_test)\n",
    "    mse, mae, r2 = evaluar_modelo(y_test, y_pred)\n",
    "\n",
    "    print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "    graficar_historial(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_otrosp(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Input\n",
    "\n",
    "def crear_modelo(entradas):\n",
    "    \"\"\"Crea un modelo de red neuronal secuencial para regresión.\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Capa de entrada\n",
    "    model.add(Dense(units = 64, activation='relu', input_dim=entradas))\n",
    "\n",
    "    model.add(Dense(units = 32, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(units = 1, activation='linear'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def entrenar_modelo(model, X_train, y_train, epochs=100):\n",
    "    \"\"\"Entrena el modelo de red neuronal y guarda el historial de entrenamiento.\"\"\"\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2)\n",
    "    return model, history\n",
    "\n",
    "def obtener_predicciones(model, X_test):\n",
    "    \"\"\"Obtiene las predicciones del modelo.\"\"\"\n",
    "    return model.predict(X_test).flatten()\n",
    "\n",
    "def evaluar_modelo(y_test, y_pred):\n",
    "    \"\"\"Evalúa el rendimiento del modelo de regresión.\"\"\"\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, mae, r2\n",
    "\n",
    "def graficar_historial(history):\n",
    "    \"\"\"Grafica el historial de entrenamiento (loss y MAE).\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Gráfica de Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss vs. Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Gráfica de MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.title('MAE vs. Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def main_otrosp(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Función principal que ejecuta todo el proceso de modelado.\"\"\"\n",
    "    model = crear_modelo(X_train.shape[1])\n",
    "    model, history = entrenar_modelo(model, X_train, y_train)\n",
    "\n",
    "    y_pred = obtener_predicciones(model, X_test)\n",
    "    mse, mae, r2 = evaluar_modelo(y_test, y_pred)\n",
    "\n",
    "    print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "    graficar_historial(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_otrosp(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
